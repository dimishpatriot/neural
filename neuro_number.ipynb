{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neuroNumber\n",
    "### Version 0.1\n",
    "The one hidden layer model for a machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_nodes, hidden_nodes, output_nodes, \n",
    "                 learn_rate):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        self.lr = learn_rate\n",
    "        \n",
    "        self.wih = numpy.random.normal(\n",
    "            0.0, \n",
    "            pow(self.hidden_nodes, -0.5),\n",
    "            (self.hidden_nodes, self.input_nodes)\n",
    "        )\n",
    "        self.who = numpy.random.normal(\n",
    "            0.0, \n",
    "            pow(self.output_nodes, -0.5),\n",
    "            (self.output_nodes, self.hidden_nodes)\n",
    "        )\n",
    "        \n",
    "        self.activation_fn = lambda x: expit(x)\n",
    "    \n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        hidden_outputs, final_outputs = self.get_outputs(inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        self.who += self.lr * numpy.dot(\n",
    "            (output_errors * final_outputs * (1.0 - final_outputs)),\n",
    "            numpy.transpose(hidden_outputs)\n",
    "            )\n",
    "        self.wih += self.lr * numpy.dot(\n",
    "            (hidden_errors * hidden_outputs * (1.0 - hidden_outputs)),\n",
    "            numpy.transpose(inputs)\n",
    "            )\n",
    "\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        _, final_outputs = self.get_outputs(inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    def get_outputs(self, inputs):\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activation_fn(hidden_inputs)\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activation_fn(final_inputs)\n",
    "        \n",
    "        return hidden_outputs, final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test data get from here:\n",
    "# https://pjreddie.com/projects/mnist-in-csv/\n",
    "# and pun in workdir\n",
    "# \n",
    "# ../\n",
    "# neuro_number.ipynb\n",
    "# mnist_test.csv\n",
    "# mnist_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING ===\n",
      "training file = mnist_train.csv\n",
      "training data length = 60000\n",
      "\n",
      "--- Model ---\n",
      "input nodes = 784\n",
      "hidden nodes = 150\n",
      "output nodes = 10\n",
      "learning rate = 0.1\n",
      "\n",
      " Epoch 1 of 5\n",
      "[0 of 60000] Training ...\n",
      "[5000 of 60000] Training ...\n",
      "[10000 of 60000] Training ...\n",
      "[15000 of 60000] Training ...\n",
      "[20000 of 60000] Training ...\n",
      "[25000 of 60000] Training ...\n",
      "[30000 of 60000] Training ...\n",
      "[35000 of 60000] Training ...\n",
      "[40000 of 60000] Training ...\n",
      "[45000 of 60000] Training ...\n",
      "[50000 of 60000] Training ...\n",
      "[55000 of 60000] Training ...\n",
      "\n",
      " Epoch 2 of 5\n",
      "[0 of 60000] Training ...\n",
      "[5000 of 60000] Training ...\n",
      "[10000 of 60000] Training ...\n",
      "[15000 of 60000] Training ...\n",
      "[20000 of 60000] Training ...\n",
      "[25000 of 60000] Training ...\n",
      "[30000 of 60000] Training ...\n",
      "[35000 of 60000] Training ...\n",
      "[40000 of 60000] Training ...\n",
      "[45000 of 60000] Training ...\n",
      "[50000 of 60000] Training ...\n",
      "[55000 of 60000] Training ...\n",
      "\n",
      " Epoch 3 of 5\n",
      "[0 of 60000] Training ...\n",
      "[5000 of 60000] Training ...\n",
      "[10000 of 60000] Training ...\n",
      "[15000 of 60000] Training ...\n",
      "[20000 of 60000] Training ...\n",
      "[25000 of 60000] Training ...\n",
      "[30000 of 60000] Training ...\n",
      "[35000 of 60000] Training ...\n",
      "[40000 of 60000] Training ...\n",
      "[45000 of 60000] Training ...\n",
      "[50000 of 60000] Training ...\n",
      "[55000 of 60000] Training ...\n",
      "\n",
      " Epoch 4 of 5\n",
      "[0 of 60000] Training ...\n",
      "[5000 of 60000] Training ...\n",
      "[10000 of 60000] Training ...\n",
      "[15000 of 60000] Training ...\n",
      "[20000 of 60000] Training ...\n",
      "[25000 of 60000] Training ...\n",
      "[30000 of 60000] Training ...\n",
      "[35000 of 60000] Training ...\n",
      "[40000 of 60000] Training ...\n",
      "[45000 of 60000] Training ...\n",
      "[50000 of 60000] Training ...\n",
      "[55000 of 60000] Training ...\n",
      "\n",
      " Epoch 5 of 5\n",
      "[0 of 60000] Training ...\n",
      "[5000 of 60000] Training ...\n",
      "[10000 of 60000] Training ...\n",
      "[15000 of 60000] Training ...\n",
      "[20000 of 60000] Training ...\n",
      "[25000 of 60000] Training ...\n",
      "[30000 of 60000] Training ...\n",
      "[35000 of 60000] Training ...\n",
      "[40000 of 60000] Training ...\n",
      "[45000 of 60000] Training ...\n",
      "[50000 of 60000] Training ...\n",
      "[55000 of 60000] Training ...\n",
      "\n",
      "=== FINISH ===\n"
     ]
    }
   ],
   "source": [
    "training_file_name = \"mnist_train.csv\"\n",
    "input_nodes = 784\n",
    "hidden_nodes = 150\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "epochs = 5\n",
    "\n",
    "with open(training_file_name, 'r') as training_data_file:\n",
    "    training_data_list = training_data_file.readlines()\n",
    "    \n",
    "\n",
    "n = Neural(input_nodes, hidden_nodes, output_nodes, \n",
    "           learning_rate)\n",
    "\n",
    "max_count = len(training_data_list)\n",
    "n.data_length = max_count\n",
    "n.training_file_name = training_file_name\n",
    "n.epochs = epochs\n",
    "\n",
    "print(\"=== TRAINING ===\")\n",
    "print(f\"training file = {n.training_file_name}\")\n",
    "print(f\"training data length = {n.data_length}\")\n",
    "print(\"\\n--- Model ---\")\n",
    "print(f\"input nodes = {n.input_nodes}\")\n",
    "print(f\"hidden nodes = {n.hidden_nodes}\")\n",
    "print(f\"output nodes = {n.output_nodes}\")\n",
    "print(f\"learning rate = {n.lr}\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(f\"\\n Epoch {e + 1} of {epochs}\")\n",
    "    count = 0\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(',')\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        if count%5000 == 0:\n",
    "            print(f\"[{count} of {max_count}] Training ...\")\n",
    "        n.train(inputs, targets)\n",
    "        count +=1\n",
    "    \n",
    "print(\"\\n=== FINISH ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST ===\n",
      "test file: mnist_test.csv\n",
      "test data: 10000 units\n",
      "correct value must be > 50.0%\n",
      "\n",
      "--- Model ---\n",
      "input nodes = 784\n",
      "hidden nodes = 150\n",
      "output nodes = 10\n",
      "learning rate = 0.1\n",
      "training file = mnist_train.csv\n",
      "training data length = 60000\n",
      "training epochs = 5\n",
      "\n",
      "[0 of 10000] Testing ...\n",
      "[1000 of 10000] Testing ...\n",
      "[2000 of 10000] Testing ...\n",
      "[3000 of 10000] Testing ...\n",
      "[4000 of 10000] Testing ...\n",
      "[5000 of 10000] Testing ...\n",
      "[6000 of 10000] Testing ...\n",
      "[7000 of 10000] Testing ...\n",
      "[8000 of 10000] Testing ...\n",
      "[9000 of 10000] Testing ...\n",
      "\n",
      "--- Report ---:\n",
      "Correct values is 9550 from 10000 (95.500%)\n",
      "\n",
      "=== FINISH ===\n"
     ]
    }
   ],
   "source": [
    "test_file_name = \"mnist_test.csv\"\n",
    "\n",
    "with open(test_file_name, 'r') as testing_data_file:\n",
    "    testing_data_list = testing_data_file.readlines()\n",
    "    \n",
    "\n",
    "max_count = len(testing_data_list)\n",
    "correct = 0.50\n",
    "\n",
    "count = 0\n",
    "good = 0\n",
    "\n",
    "print(\"=== TEST ===\")\n",
    "print(f\"test file: {test_file_name}\")\n",
    "print(f\"test data: {max_count} units\")\n",
    "print(f\"correct value must be > {correct * 100}%\")\n",
    "print(\"\\n--- Model ---\")\n",
    "print(f\"input nodes = {n.input_nodes}\")\n",
    "print(f\"hidden nodes = {n.hidden_nodes}\")\n",
    "print(f\"output nodes = {n.output_nodes}\")\n",
    "print(f\"learning rate = {n.lr}\")\n",
    "print(f\"training file = {n.training_file_name}\")\n",
    "print(f\"training data length = {n.data_length}\")\n",
    "print(f\"training epochs = {n.epochs}\")\n",
    "        \n",
    "print()\n",
    "\n",
    "for record in testing_data_list:\n",
    "    all_values = record.split(',')\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    if count%1000 == 0:\n",
    "        print(f\"[{count} of {max_count}] Testing ...\")\n",
    "    \n",
    "    res = list(n.query(inputs))\n",
    "    max_value = max(res)\n",
    "    idx = res.index(max_value)\n",
    "    number = int(all_values[0])\n",
    "    if (float(max_value) > correct) and idx == number:\n",
    "        good += 1\n",
    "        \n",
    "    count +=1\n",
    "\n",
    "print(\"\\n--- Report ---:\")\n",
    "print(f\"Correct values is {good} from {max_count} ({good/max_count * 100:.3f}%)\")\n",
    "print(\"\\n=== FINISH ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency ~95-96%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

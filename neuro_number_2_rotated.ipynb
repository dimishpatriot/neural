{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neuroNumber 2 rotated\n",
    "### Version 0.1\n",
    "The two hidden layers model for a machine learning.\n",
    "\n",
    "In training process each unit used in -10/0/10 deg. positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.ndimage\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_nodes: int,\n",
    "                 hidden_nodes_1: int, \n",
    "                 hidden_nodes_2: int,\n",
    "                 output_nodes: int, \n",
    "                 learn_rate: float):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes_1 = hidden_nodes_1\n",
    "        self.hidden_nodes_2 = hidden_nodes_2\n",
    "        self.output_nodes = output_nodes\n",
    "        self.lr = learn_rate\n",
    "        \n",
    "        self.wih = numpy.random.normal(\n",
    "            0.0, \n",
    "            pow(self.hidden_nodes_1, -0.5),\n",
    "            (self.hidden_nodes_1, self.input_nodes)\n",
    "        )\n",
    "        \n",
    "        self.whh = numpy.random.normal(\n",
    "            0.0, \n",
    "            pow(self.hidden_nodes_2, -0.5),\n",
    "            (self.hidden_nodes_2, self.hidden_nodes_1)\n",
    "        )\n",
    "        \n",
    "        self.who = numpy.random.normal(\n",
    "            0.0, \n",
    "            pow(self.output_nodes, -0.5),\n",
    "            (self.output_nodes, self.hidden_nodes_2)\n",
    "        )\n",
    "        \n",
    "        self.activation_fn = lambda x: expit(x)\n",
    "    \n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        hidden_outputs_1, \\\n",
    "        hidden_outputs_2, \\\n",
    "        final_outputs = self.get_outputs(inputs)\n",
    "        \n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors_2 = numpy.dot(self.who.T, output_errors)\n",
    "        hidden_errors_1 = numpy.dot(self.whh.T, hidden_errors_2)\n",
    "        \n",
    "        self.who += self.lr * numpy.dot(\n",
    "            (output_errors * final_outputs * (1.0 - final_outputs)),\n",
    "            numpy.transpose(hidden_outputs_2)\n",
    "            )\n",
    "        \n",
    "        self.whh += self.lr * numpy.dot(\n",
    "            (hidden_errors_2 * hidden_outputs_2 * (1.0 - hidden_outputs_2)),\n",
    "            numpy.transpose(hidden_outputs_1)\n",
    "            )\n",
    "        \n",
    "        self.wih += self.lr * numpy.dot(\n",
    "            (hidden_errors_1 * hidden_outputs_1 * (1.0 - hidden_outputs_1)),\n",
    "            numpy.transpose(inputs)\n",
    "            )\n",
    "\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        _, _, final_outputs = self.get_outputs(inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    def get_outputs(self, inputs):\n",
    "        hidden_inputs_1 = numpy.dot(self.wih, inputs)\n",
    "        hidden_outputs_1 = self.activation_fn(hidden_inputs_1)\n",
    "        \n",
    "        hidden_inputs_2 = numpy.dot(self.whh, hidden_outputs_1)\n",
    "        hidden_outputs_2 = self.activation_fn(hidden_inputs_2)\n",
    "        \n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs_2)\n",
    "        final_outputs = self.activation_fn(final_inputs)\n",
    "        \n",
    "        return hidden_outputs_1, hidden_outputs_2, final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test data get from here:\n",
    "# https://pjreddie.com/projects/mnist-in-csv/\n",
    "# and pun in workdir\n",
    "# \n",
    "# ../\n",
    "# neuro_number.ipynb\n",
    "# mnist_test.csv\n",
    "# mnist_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING ===\n",
      "training file = mnist_train.csv\n",
      "training data length = 60000 + 2 rotation each (+/- 10 deg.)\n",
      "start: 12/03/2020, 11:28:08\n",
      "\n",
      "--- Model ---\n",
      "input nodes = 784\n",
      "hidden nodes 1 = 196\n",
      "hidden nodes 2 = 49\n",
      "output nodes = 10\n",
      "learning rate = 0.01\n",
      "\n",
      "--- Epoch 1 of 4 ---\n",
      "[1 of 60000] Training ...\n",
      "[5001 of 60000] Training ...\n",
      "[10001 of 60000] Training ...\n",
      "[15001 of 60000] Training ...\n",
      "[20001 of 60000] Training ...\n",
      "[25001 of 60000] Training ...\n",
      "[30001 of 60000] Training ...\n",
      "[35001 of 60000] Training ...\n",
      "[40001 of 60000] Training ...\n",
      "[45001 of 60000] Training ...\n",
      "[50001 of 60000] Training ...\n",
      "[55001 of 60000] Training ...\n",
      "\n",
      "--- Epoch 2 of 4 ---\n",
      "[1 of 60000] Training ...\n",
      "[5001 of 60000] Training ...\n",
      "[10001 of 60000] Training ...\n",
      "[15001 of 60000] Training ...\n",
      "[20001 of 60000] Training ...\n",
      "[25001 of 60000] Training ...\n",
      "[30001 of 60000] Training ...\n",
      "[35001 of 60000] Training ...\n",
      "[40001 of 60000] Training ...\n",
      "[45001 of 60000] Training ...\n",
      "[50001 of 60000] Training ...\n",
      "[55001 of 60000] Training ...\n",
      "\n",
      "--- Epoch 3 of 4 ---\n",
      "[1 of 60000] Training ...\n",
      "[5001 of 60000] Training ...\n",
      "[10001 of 60000] Training ...\n",
      "[15001 of 60000] Training ...\n",
      "[20001 of 60000] Training ...\n",
      "[25001 of 60000] Training ...\n",
      "[30001 of 60000] Training ...\n",
      "[35001 of 60000] Training ...\n",
      "[40001 of 60000] Training ...\n",
      "[45001 of 60000] Training ...\n",
      "[50001 of 60000] Training ...\n",
      "[55001 of 60000] Training ...\n",
      "\n",
      "--- Epoch 4 of 4 ---\n",
      "[1 of 60000] Training ...\n",
      "[5001 of 60000] Training ...\n",
      "[10001 of 60000] Training ...\n",
      "[15001 of 60000] Training ...\n",
      "[20001 of 60000] Training ...\n",
      "[25001 of 60000] Training ...\n",
      "[30001 of 60000] Training ...\n",
      "[35001 of 60000] Training ...\n",
      "[40001 of 60000] Training ...\n",
      "[45001 of 60000] Training ...\n",
      "[50001 of 60000] Training ...\n",
      "[55001 of 60000] Training ...\n",
      "end time: 12/03/2020, 11:51:09\n",
      "elapsed time: 1381.29 sec.\n",
      "\n",
      "=== FINISH ===\n"
     ]
    }
   ],
   "source": [
    "# Layers\n",
    "input_nodes = 784     # 28*28 - sample size\n",
    "hidden_nodes_1 = 196  # 784/4\n",
    "hidden_nodes_2 = 49   # 196/4\n",
    "output_nodes = 10     # n-digits\n",
    "\n",
    "# Training dataset (60_000)\n",
    "training_file_name = \"mnist_train.csv\"\n",
    "with open(training_file_name, 'r') as training_data_file:\n",
    "    training_data_list = training_data_file.readlines()\n",
    "data_length = len(training_data_list)\n",
    "    \n",
    "# Init model\n",
    "n = Neural(input_nodes, \n",
    "           hidden_nodes_1,\n",
    "           hidden_nodes_2,\n",
    "           output_nodes, \n",
    "           learning_rate)\n",
    "\n",
    "# Training settings\n",
    "learning_rate = 0.012\n",
    "epochs = 4\n",
    "part_of_data_to_train = 1   # setup part of training dataset 0-1\n",
    "max_count = int(data_length * part_of_data_to_train)\n",
    "\n",
    "# Addition info to object\n",
    "n.data_length = max_count\n",
    "n.training_file_name = training_file_name\n",
    "n.epochs = epochs\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Intro\n",
    "print(\"=== TRAINING ===\")\n",
    "print(f\"training file = {n.training_file_name}\")\n",
    "print(f\"training data length = {n.data_length} + 2 rotation each (+/- 10 deg.)\")\n",
    "print(f\"start: {time.strftime('%m/%d/%Y, %H:%M:%S', time.localtime())}\")\n",
    "print(\"\\n--- Model ---\")\n",
    "print(f\"input nodes = {n.input_nodes}\")\n",
    "print(f\"hidden nodes 1 = {n.hidden_nodes_1}\")\n",
    "print(f\"hidden nodes 2 = {n.hidden_nodes_2}\")\n",
    "print(f\"output nodes = {n.output_nodes}\")\n",
    "print(f\"learning rate = {n.lr}\")\n",
    "\n",
    "# Training\n",
    "for e in range(epochs):\n",
    "    print(f\"\\n--- Epoch {e + 1} of {epochs} ---\")\n",
    "    \n",
    "    count = 0\n",
    "    for record in training_data_list[:max_count]:\n",
    "        all_values = record.split(',')\n",
    "        \n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        \n",
    "        if count%5000 == 0:\n",
    "            print(f\"[{count + 1} of {max_count}] Training ...\")\n",
    "        \n",
    "        inputs_orig = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        n.train(inputs_orig, targets)\n",
    "        \n",
    "        inputs_reshape = inputs_orig.reshape(28, 28)\n",
    "        \n",
    "        inputs_plus10 = scipy.ndimage.interpolation.rotate(\n",
    "            inputs_reshape, \n",
    "            10, \n",
    "            cval=0.01, \n",
    "            reshape=False\n",
    "        ).reshape(784)\n",
    "        n.train(inputs_plus10, targets)\n",
    "        \n",
    "        inputs_minus10 = scipy.ndimage.interpolation.rotate(\n",
    "            inputs_reshape, \n",
    "            -10, \n",
    "            cval=0.01, \n",
    "            reshape=False\n",
    "        ).reshape(784)\n",
    "        n.train(inputs_minus10, targets)\n",
    "        \n",
    "        count +=1\n",
    "\n",
    "# Outro\n",
    "end_time = time.time()\n",
    "print(f\"end time: {time.strftime('%m/%d/%Y, %H:%M:%S', time.localtime())}\")\n",
    "print(f\"elapsed time: {end_time - start_time:.2f} sec.\")\n",
    "print(\"\\n=== FINISH ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST ===\n",
      "test file: mnist_test.csv\n",
      "test data: 10000 units\n",
      "correct value must be > 50.0%\n",
      "start: 12/03/2020, 11:51:50\n",
      "\n",
      "--- Model ---\n",
      "input nodes = 784\n",
      "hidden nodes 1 = 196\n",
      "hidden nodes 2 = 49\n",
      "output nodes = 10\n",
      "learning rate = 0.01\n",
      "training file = mnist_train.csv\n",
      "training data length = 60000\n",
      "training epochs = 4\n",
      "[1 of 10000] Testing ...\n",
      "[1001 of 10000] Testing ...\n",
      "[2001 of 10000] Testing ...\n",
      "[3001 of 10000] Testing ...\n",
      "[4001 of 10000] Testing ...\n",
      "[5001 of 10000] Testing ...\n",
      "[6001 of 10000] Testing ...\n",
      "[7001 of 10000] Testing ...\n",
      "[8001 of 10000] Testing ...\n",
      "[9001 of 10000] Testing ...\n",
      "\n",
      "--- Report ---\n",
      "end time: 12/03/2020, 11:51:54\n",
      "elapsed time: 3.99 sec.\n",
      "correct values is 9603 from 10000 (96.030%)\n",
      "\n",
      "=== FINISH ===\n"
     ]
    }
   ],
   "source": [
    "test_file_name = \"mnist_test.csv\"\n",
    "\n",
    "with open(test_file_name, 'r') as testing_data_file:\n",
    "    testing_data_list = testing_data_file.readlines()\n",
    "    \n",
    "\n",
    "data_length = len(testing_data_list)\n",
    "max_count = 10000\n",
    "correct = 0.50\n",
    "\n",
    "count = 0\n",
    "good = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"=== TEST ===\")\n",
    "print(f\"test file: {test_file_name}\")\n",
    "print(f\"test data: {max_count} units\")\n",
    "print(f\"correct value must be > {correct * 100}%\")\n",
    "print(f\"start: {time.strftime('%m/%d/%Y, %H:%M:%S', time.localtime())}\")\n",
    "      \n",
    "print(\"\\n--- Model ---\")\n",
    "print(f\"input nodes = {n.input_nodes}\")\n",
    "print(f\"hidden nodes 1 = {n.hidden_nodes_1}\")\n",
    "print(f\"hidden nodes 2 = {n.hidden_nodes_2}\")\n",
    "print(f\"output nodes = {n.output_nodes}\")\n",
    "print(f\"learning rate = {n.lr}\")\n",
    "print(f\"training file = {n.training_file_name}\")\n",
    "print(f\"training data length = {n.data_length}\")\n",
    "print(f\"training epochs = {n.epochs}\")\n",
    "        \n",
    "for record in testing_data_list[:max_count]:\n",
    "    all_values = record.split(',')\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    \n",
    "    if count%1000 == 0:\n",
    "        print(f\"[{count + 1} of {max_count}] Testing ...\")\n",
    "    \n",
    "    res = list(n.query(inputs))\n",
    "    max_value = max(res)\n",
    "    idx = res.index(max_value)\n",
    "    number = int(all_values[0])\n",
    "    if (float(max_value) > correct) and idx == number:\n",
    "        good += 1\n",
    "        \n",
    "    count +=1\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Outro\n",
    "print(\"\\n--- Report ---\")\n",
    "print(f\"end time: {time.strftime('%m/%d/%Y, %H:%M:%S', time.localtime())}\")\n",
    "print(f\"elapsed time: {end_time - start_time:.2f} sec.\")\n",
    "print(f\"correct values is {good} from {max_count} ({good/max_count * 100:.3f}%)\")\n",
    "print(\"\\n=== FINISH ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency >96%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
